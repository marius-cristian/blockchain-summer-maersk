\section{A centralised point of view}
In the current scheme, the ERP system is the central authority, that deals with the manangement of data from subsidiaries (we can treat it as a special join table from a relational database that also contains the privilege level of its subsidiaries). The main concerns are: the data is not immutable on each of the subsidiaries and the subsidiaries might be out of sync. Thus a request can return either "not found", invalid data or valid data. Making the transactions immutable solves the "not found" branch, but there is no feasible way to distinguish between invalid and valid data.\\

\subsection{Immutable data}
The first step is to ensure that data cannot dissapear. Implementing a database (with timestamped operations) at node (subsidiary) level, that can only Read, Create and Update guarantees that the data will not be accidentally deleted. The timestamp ensures that the transactions can be traced back in time, and that there can be set a priority protocol, such that the modifications must be in chronological order. What if there are two ongoing modifications (each on different subsidiaries) that are interdependent, how would this affect the validity of the data?
\subsection{Keeping data in sync}
Besides the timestamp, the second step is to introduce a locking mechanism, to ensure the validity of the interdependent data. This would be done at ERP level as follows:\\
Every operation at node level is forced to report back to the ERP the type of operation and the timestamp and in the case of a requested Update operation, it must wait for all of the other Update operations to finish. This will create a bottleneck, as not all of the data is interdependant. A better approach would be to implement a locking protocol on attribute (collumn in the database) level, but this would be very hard to keep track of, especially that the data is not handled at transaction level, but bundles of transactions.\\
Besides the initial permission protocol, now there is a locking protocol at ERP level as well.\\
\subsection{Bundles of transactions}
At individual transaction level:\\
The CREATE operation, just instantiates a new transaction, therefore it is considered safe (the worst case is when dealing with offline transactions, that need to be added manually by a human, as they might misstype it). The READ operation is also considered safe, as it does not modify the state. If a transactions data is under modification in the locking table, it can also be marked with a read-warning flag. Our main concern is the UPDATE operation. The modifications are done asynchronously, thus when commiting them there might be a conflict (another entity commited a new version before the current one was submitted), thus it should not be accepted, because it's validity is questionable.\\
\\
When dealing with bundles of transactions there should be a merge protocol defined at the ERP level, such that it will only commit and update the timestamps of the transactions that are valid for sure, and return back to the node the ones that failed. The node then has to READ the data again, and apply the modifications again to the transactions that had discrepancies between the two reads. Hopefully this will not be a frustrating process for the person who edits the data, as it can be tuned at interface level, and the volume might not be that big. This paper cannot make further analysis on the topic as some facts are not known.\\
\subsection{Conclusion}
This might provide a good starting point as there are no major security flaws on the system level, it assumes a certain level of automatization (transactions are stored automatically when a payement is done through the system), everything is closed, only humans can decide what to do with the data (leak it or not). It is possible to trace back a transaction back in time, and provide a full report on how it was modified, but there are still some questions:\\
What if a subsidiary dissapears, or because of natural reasons, it loses it's data storage? Should there be a replication mechanism?\\
A tax authority might not trust this hermetic system.\\
The timestamps can be forged.\\
The volume of transactions might be too big and it might take too much time to keep track of the modification; there is a big bottleneck at ERP level, with each node (subsidiary) that wants to modify the same data.\\